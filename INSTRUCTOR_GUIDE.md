# CASP SR Response Viewer - Instructor Guide

A comprehensive guide for using the CASP Systematic Reviews Response Viewer in classroom settings.

## Overview

The CASP SR Response Viewer transforms student critical appraisals into an interactive learning experience. It displays anonymized responses to 10 SR questions, enables peer voting, and provides real-time statistics for classroom discussion.

## Pre-Class Setup (Day Before)

### 1. Verify System Requirements

- [ ] Classroom projector or large display
- [ ] Instructor computer with internet
- [ ] Student devices (phones/laptops) optional
- [ ] Chrome or Firefox browser

### 2. Test the Viewer

1. Open the viewer URL
2. Navigate through all 10 questions
3. Test voting on a few responses
4. Check statistics display
5. Verify auto-refresh works

### 3. Prepare Discussion Points

Review common issues in SR appraisals:
- Question 1: PECO framework understanding
- Question 3: Search comprehensiveness
- Question 4: Quality assessment methods
- Question 5: Heterogeneity and meta-analysis
- Question 10: Risk-benefit analysis

## Classroom Facilitation Guide

### Opening (5 minutes)

1. **Project the viewer** on main screen
2. **Explain the interface**:
   - "We'll review your SR appraisals together"
   - "All responses are anonymized"
   - "Vote for explanations you find particularly insightful"
   - "We'll discuss patterns and exemplars"

3. **Set expectations**:
   - Respectful critique
   - Focus on reasoning, not right/wrong
   - Learning from peer approaches

### Question-by-Question Review (4-5 minutes each)

#### For Each Question:

1. **Read the question aloud**
2. **Show CONSIDER prompts** (click toggle)
3. **Review statistics first**:
   - "Let's see the answer distribution"
   - Discuss if skewed heavily one way
4. **Filter responses** if needed:
   - Start with "Can't Tell" to address uncertainty
   - Then "No" responses for critique
   - Finally "Yes" for confirmation
5. **Highlight top-voted responses**:
   - "Student 7 received the most votes, let's see why"
   - Read explanation aloud
   - Discuss reasoning quality

### Using Statistics (Throughout)

Click "üìä Show Statistics" to reveal:

#### Answer Distribution
- **Consensus** (>80% same answer): "Strong agreement on this question"
- **Split** (roughly even): "Interesting divergence - let's explore why"
- **High uncertainty** (many Can't Tell): "What information was missing?"

#### Top Voted Responses
- "These explanations resonated with your peers"
- Use as exemplars
- Discuss what makes them effective

#### Uncertainty Analysis
- Identify questions with most "Can't Tell"
- Address knowledge gaps
- Clarify CASP criteria

## Interactive Activities

### Activity 1: Peer Voting (10 minutes)

1. **Instructions to students**:
   - "Take 5 minutes to read through Question 3 responses"
   - "Vote for the explanation that best justifies the answer"
   - "You can vote once per response"

2. **Live monitoring**:
   - Watch votes accumulate in real-time
   - Auto-refresh shows changes

3. **Discussion**:
   - "Let's look at the top 3 voted responses"
   - "What makes these explanations strong?"

### Activity 2: Filter Challenge (5 minutes)

1. **Set a filter** (e.g., "No" responses only)
2. **Challenge**: "Find the response that best explains why studies weren't comprehensive"
3. **Discuss** common themes in filtered responses

### Activity 3: Can't Tell Analysis (10 minutes)

1. **Show uncertainty chart** in statistics
2. **Focus on highest** "Can't Tell" question
3. **Discussion prompts**:
   - "What information would you need?"
   - "Is this the paper's fault or limitation of reporting?"
   - "How would you find this information?"

## Question-Specific Teaching Points

### Question 1: Clearly Focused Question
- Emphasize PECO framework
- Show examples of well-formulated questions
- Discuss importance of specificity

### Question 2: Right Type of Papers
- RCTs for interventions
- Observational for etiology/prognosis
- Match design to question

### Question 3: Comprehensive Search
- Multiple databases essential
- Grey literature importance
- Language bias risks

### Question 4: Quality Assessment
- Risk of bias tools
- GRADE approach
- Critical vs accepting reading

### Question 5: Combining Results
- Statistical heterogeneity (I¬≤)
- Clinical heterogeneity
- When NOT to pool

### Question 6: Overall Results
- Forest plots interpretation
- Effect sizes and clinical significance
- NNT calculations

### Question 7: Precision
- Confidence intervals width
- Sample size impact
- Precision vs accuracy

### Question 8: Local Applicability
- Population differences
- Healthcare system variations
- Resource availability

### Question 9: Important Outcomes
- Patient-centered outcomes
- Surrogate vs clinical endpoints
- Missing outcomes

### Question 10: Benefits vs Harms
- Absolute vs relative risk
- Number needed to harm
- Economic considerations

## Managing Common Scenarios

### Scenario 1: No Clear Consensus

**Approach**:
- "This divergence is interesting"
- Explore different interpretations
- Emphasize critical thinking over consensus

### Scenario 2: All "Can't Tell"

**Approach**:
- Validates difficulty of appraisal
- Discuss reporting quality issues
- Show how to find missing information

### Scenario 3: Excellent Response

**Approach**:
- Highlight without identifying student
- Break down what makes it excellent
- Use as template for future work

### Scenario 4: Common Misconception

**Approach**:
- Address generally, not specifically
- "I notice several responses mention..."
- Clarify the concept thoroughly

## Technical Tips

### Projector Settings

- **Resolution**: 1920√ó1080 preferred
- **Zoom**: 100% for best layout
- **Browser**: Full screen (F11)

### Navigation Shortcuts

- **Arrow keys**: Previous/Next question
- **Number keys**: Jump to question (1-9, 0 for 10)
- **Escape**: Close statistics modal

### If Technical Issues

**Viewer won't load**:
1. Check internet connection
2. Try incognito mode
3. Clear browser cache
4. Have backup: PDF of responses

**Votes not working**:
- Continue without voting
- Ask for verbal feedback instead
- Note for technical support later

## Post-Class Actions

### 1. Export Statistics

- Screenshot statistics for each question
- Note questions with most uncertainty
- Document exemplar responses

### 2. Follow-up Communication

Email students:
- Highlight excellent reasoning examples
- Clarify common misconceptions
- Provide additional resources for gaps

### 3. Improve Next Iteration

Track:
- Questions causing most difficulty
- Technical issues encountered
- Successful discussion prompts

## Time Management Guide

### 50-Minute Class

| Time | Activity |
|------|----------|
| 0-5 min | Introduction and interface overview |
| 5-10 min | Question 1 with CONSIDER prompts |
| 10-20 min | Questions 2-4 (high importance) |
| 20-25 min | Peer voting activity |
| 25-35 min | Questions 5-7 with statistics |
| 35-40 min | Questions 8-10 (rapid review) |
| 40-45 min | Uncertainty analysis |
| 45-50 min | Summary and key takeaways |

### 90-Minute Class

| Time | Activity |
|------|----------|
| 0-10 min | Introduction and warm-up |
| 10-40 min | Questions 1-5 detailed review |
| 40-50 min | Break and peer voting |
| 50-70 min | Questions 6-10 review |
| 70-80 min | Statistics deep dive |
| 80-90 min | Summary and reflection |

## Assessment Integration

### Formative Assessment

- Monitor voting patterns
- Note quality of justifications
- Identify students needing support
- Track improvement over semester

### Summative Considerations

- Don't grade based on viewer responses
- Use as learning tool only
- Consider peer feedback in participation marks
- Document excellent examples for rubrics

## Privacy & Ethics

### Do's
- ‚úÖ Keep responses anonymized
- ‚úÖ Focus on learning, not judgment
- ‚úÖ Celebrate good reasoning
- ‚úÖ Address misconceptions generally

### Don'ts
- ‚ùå Never reveal student identities
- ‚ùå Don't shame poor responses
- ‚ùå Avoid making voting competitive
- ‚ùå Don't save/share identified data

## Troubleshooting FAQ

**Q: Students can't vote**
A: LocalStorage may be blocked. Have them try different browser or clear cookies.

**Q: Responses aren't updating**
A: Toggle auto-refresh or manually refresh page.

**Q: Statistics won't display**
A: Check if Chart.js loaded. Try different browser.

**Q: Wrong number of questions**
A: Verify SR form has 10 questions. Check Code.gs configuration.

## Tips for Success

1. **Practice beforehand** - Know the interface well
2. **Have backup plan** - Technical issues happen
3. **Encourage participation** - But don't force it
4. **Focus on learning** - Not performance
5. **Be flexible** - Adapt to class dynamics
6. **Document insights** - For curriculum improvement

## Support Resources

- Technical issues: Check DEPLOYMENT.md
- Pedagogical questions: CASP official guidelines
- System modifications: See README.md

---

**Version**: 1.0.0
**For**: CASP SR Response Viewer
**Updated**: November 2024